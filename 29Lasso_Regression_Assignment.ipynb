{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ba5dd3-4e86-4fec-992e-6cd8333a5e3c",
   "metadata": {},
   "source": [
    "#1\n",
    "\n",
    "What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "---\n",
    "---\n",
    "Lasso Regression, also known as L1 regularization.The primary goal of LASSO regression is to find a balance between model simplicity and accuracy. It achieves this by adding a penalty term to the traditional linear regression model, which encourages sparse solutions where some coefficients are forced to be exactly zero. This feature makes LASSO particularly useful for feature selection, as it can automatically identify and discard irrelevant or redundant variables.\n",
    "\n",
    "The main difference between Ridge and Lasso regression is in the way they shrink the coefficients. Ridge regression can reduce all the coefficients by a small amount but Lasso can reduce some features more than others and hence can completely eliminate those features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32951b-a686-4aca-8d0e-208d0d731e3a",
   "metadata": {},
   "source": [
    "#2\n",
    "\n",
    "What is the main advantage of using Lasso Regression in feature selection?\n",
    "---\n",
    "---\n",
    "The main advantage of using Lasso Regression in feature selection is its ability to perform automatic feature selection. This is because Lasso Regression can shrink some of the coefficient estimates to exactly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63ceaf-3ee4-4d36-b089-82a1133edb9b",
   "metadata": {},
   "source": [
    "#3\n",
    "\n",
    "How do you interpret the coefficients of a Lasso Regression model?\n",
    "----\n",
    "----\n",
    "Lasso regression is a statistical method for performing linear regression while simultaneously imposing a penalty on the absolute values of the coefficients. This penalty term, known as the L1 penalty, encourages the model to select only the most important features and discard the rest.\n",
    "\n",
    "As a result, some of the coefficients in a Lasso regression model will be set to zero. This means that the corresponding features have been excluded from the model because they are not considered to be important for predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3731522-0863-48fa-b13b-8c3c213875fe",
   "metadata": {},
   "source": [
    "#4\n",
    "\n",
    "What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "---\n",
    "---\n",
    "In Lasso Regression, there are several tuning parameters that can be adjusted to affect the model's performance:\n",
    "\n",
    "1. λ: This is the main tuning parameter in Lasso Regression. It controls the strength of the penalty term, which is the L1 regularization term in the case of Lasso. The alpha parameter must be a non-negative float¹. When alpha is 0, the objective is equivalent to ordinary least squares, solved by the LinearRegression object. However, for numerical reasons, using alpha = 0 with the Lasso object is not advised. Instead, you should use the LinearRegression object. As alpha increases, more coefficients are shrunk to zero, leading to a simpler and more interpretable model but potentially also to underfitting.\n",
    "\n",
    "2. Max_iter: This is the maximum number of iterations for the solver to converge.\n",
    "\n",
    "3. Tol: This is the tolerance for stopping criteria. If the updates are smaller than tol, the optimization code checks the dual gap for optimality and continues until it is smaller than tol.\n",
    "\n",
    "4. Selection: If set to 'random', a random coefficient is updated every iteration rather than looping over features sequentially by default. This often leads to significantly faster convergence especially when tol is higher than 1e-4.\n",
    "\n",
    "5. Positive: When set to True, forces the coefficients to be positive.\n",
    "\n",
    "6. Fit_intercept: Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e., data is expected to be centered)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20806c0c-2d23-45b0-81d7-0554a1afa509",
   "metadata": {},
   "source": [
    "#5\n",
    "\n",
    "Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "---\n",
    "---\n",
    "\n",
    "Yes, Lasso regression can be used for non-linear regression problems. One way to do this is to transform the input features into a higher-dimensional space using basis functions. Basis functions are functions that are used to represent more complex functions as a linear combination of simpler functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc897e95-a2ab-4f50-babc-8ad8ed2085f0",
   "metadata": {},
   "source": [
    "#6\n",
    "\n",
    "What is the difference between Ridge Regression and Lasso Regression?\n",
    "---\n",
    "---\n",
    "The difference between Ridge and Lasso regression is in the way they shrink the coefficients. Ridge regression can reduce all the coefficients by a small amount but Lasso can reduce some features more than others and hence can completely eliminate those features.\n",
    "\n",
    "In ridge regression, the complexity of the model is reduced by decreasing the magnitude of coefficients, but it never sets the value of coefficients to absolute zero. Whereas lasso regression tends to make coefficients absolute zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723419ea-aece-48b5-8605-4df685ce8dec",
   "metadata": {},
   "source": [
    "#7\n",
    "\n",
    "Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "---\n",
    "---\n",
    "The L1 penalty used in Lasso Regression has the effect of shrinking some of the coefficient estimates to exactly zero when multicollinearity is present. This means that Lasso can exclude these collinear features from the model.\n",
    "\n",
    "This property of Lasso Regression makes it particularly useful when dealing with datasets that have multicollinearity. It not only simplifies the model but also improves interpretability and can help prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f700e-872c-4bef-be3f-d3eeeefe9259",
   "metadata": {},
   "source": [
    "#8\n",
    "\n",
    "How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "---\n",
    "---\n",
    "There are several methods to determine the optimal lambda value:\n",
    "\n",
    "Cross-Validation: This is the most common method for choosing the optimal lambda. In this method, you define a grid of lambda values and calculate the validation Mean Squared Error (MSE) within each fold. Then, you calculate the overall cross-validation MSE and locate under which lambda the cross-validation MSE is minimized. This value of lambda is known as the lambda.min.\n",
    "\n",
    "One Standard Error Rule: Another common approach is to choose the lambda value with the greatest amount of shrinkage whose Cross-Validation Mean Squared Error (CVMSE) is within one standard error of the minimum.\n",
    "\n",
    "Solver: In some cases, you can use a solver to find the optimal lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d512906-2182-44dd-9921-62c36d9309b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
